{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6/anaconda3/envs/LDS/lib/python3.9/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X26-1498.40m1-: Number of masks generated: 762\n",
      "X53-1697.98m2-: Number of masks generated: 936\n",
      "X26-1604.43m1-: Number of masks generated: 564\n",
      "X40-2001.10m1-: Number of masks generated: 510\n",
      "X18-1369.20m1-: Number of masks generated: 1014\n",
      "X159-1253.78m1-: Number of masks generated: 734\n",
      "X51-1633.71m1-: Number of masks generated: 531\n",
      "X41-1936.00m1-: Number of masks generated: 387\n",
      "X12-2064.00m1-: Number of masks generated: 349\n",
      "X53-1696.79m1-: Number of masks generated: 548\n",
      "X21-1655.27m1-: Number of masks generated: 512\n",
      "X45-1772.50m1-: Number of masks generated: 299\n",
      "X48-1547.90m1-: Number of masks generated: 1158\n",
      "X151-1845.31m1-: Number of masks generated: 515\n",
      "X26-1930.40m1-: Number of masks generated: 550\n",
      "X16-1870.11m1-: Number of masks generated: 365\n",
      "X46-1565.86m2-: Number of masks generated: 656\n",
      "X48-1623.65m1-: Number of masks generated: 737\n",
      "X45-1874.50m1-: Number of masks generated: 354\n",
      "X31-1581.50m1-: Number of masks generated: 531\n",
      "X51-1859.10m1-: Number of masks generated: 1613\n",
      "X53-1480.55m1-: Number of masks generated: 884\n",
      "X31-1373.50m1-: Number of masks generated: 507\n",
      "X16-1448.48m1-: Number of masks generated: 475\n",
      "X26-1825.80m1-: Number of masks generated: 494\n",
      "X31-1376.50m1-: Number of masks generated: 677\n",
      "X20-1781.38m1-: Number of masks generated: 955\n",
      "X10-1104.40m1-: Number of masks generated: 573\n",
      "X45-1660.84m1-: Number of masks generated: 592\n",
      "X41-1653.20m1-: Number of masks generated: 378\n",
      "X46-1612.72m2-: Number of masks generated: 861\n",
      "X53-1699.76m1-: Number of masks generated: 421\n",
      "X46-1609.53m1-: Number of masks generated: 969\n",
      "X26-1929.50m1-: Number of masks generated: 419\n",
      "X41-2001.20m1-: Number of masks generated: 322\n",
      "X9-1303.11m2-: Number of masks generated: 326\n",
      "X55-1805.00m2-: Number of masks generated: 565\n",
      "X10-1102.70m1-: Number of masks generated: 339\n",
      "X41-1737.40m1-: Number of masks generated: 492\n",
      "X159-1257.19m1-: Number of masks generated: 658\n",
      "X55-1407.10m1-: Number of masks generated: 1020\n",
      "X151-1844.27m-1-: Number of masks generated: 809\n",
      "X159-1253.08m1-: Number of masks generated: 659\n",
      "X16-1871.16m1-: Number of masks generated: 800\n",
      "X151-1848.91m1-: Number of masks generated: 756\n",
      "X16-1989.32m1-: Number of masks generated: 478\n",
      "X53-1652.54m1-: Number of masks generated: 650\n",
      "X41-1686.00m1-: Number of masks generated: 811\n",
      "X10-1280.70m1-: Number of masks generated: 406\n",
      "X55-1499.00m1-: Number of masks generated: 897\n",
      "X41-1898.10m1-: Number of masks generated: 481\n",
      "X159-1355.77m1-: Number of masks generated: 1077\n",
      "X41-1654.50m1-: Number of masks generated: 570\n",
      "X46-1608.10m1-: Number of masks generated: 676\n",
      "X53-1695.50m1-: Number of masks generated: 573\n",
      "X55-1494.90m2-: Number of masks generated: 529\n",
      "X48-1842.93m2-: Number of masks generated: 977\n",
      "X41-1728.60m1-: Number of masks generated: 459\n",
      "X18-1901.66m1-: Number of masks generated: 542\n",
      "X51-1858.40m1-: Number of masks generated: 1350\n",
      "X45-1660.21m1-: Number of masks generated: 497\n",
      "X48-1840.12m1-: Number of masks generated: 888\n",
      "X159-1257.85m1-: Number of masks generated: 612\n",
      "X51-2027.53m1-: Number of masks generated: 1154\n",
      "X41-1682.60m1-: Number of masks generated: 438\n",
      "X9-1825.80m1-: Number of masks generated: 444\n",
      "X41-1655.60m1-: Number of masks generated: 731\n",
      "X51-1634.01m1-: Number of masks generated: 1494\n",
      "X53-1697.98m1-: Number of masks generated: 746\n",
      "X41-2010.40m1-: Number of masks generated: 826\n",
      "X53-1692.25m1-: Number of masks generated: 465\n",
      "X53-1696.43m2-: Number of masks generated: 613\n",
      "X23-1356.09m1-: Number of masks generated: 511\n",
      "X31-1594.00m1-: Number of masks generated: 636\n",
      "X26-1348.60m1-: Number of masks generated: 690\n",
      "X16-2084.55m1-: Number of masks generated: 428\n",
      "X53-1699.02m1-: Number of masks generated: 772\n",
      "X18-1550.60m1-: Number of masks generated: 582\n",
      "X55-1805.00m1-: Number of masks generated: 645\n",
      "X17-1675.60m1-: Number of masks generated: 711\n",
      "X159-1254.56m1-: Number of masks generated: 620\n",
      "X31-1228.50m1-: Number of masks generated: 596\n",
      "X41-2175.60m1-: Number of masks generated: 853\n",
      "X16-1764.71m1-: Number of masks generated: 346\n",
      "X41-1735.20m1-: Number of masks generated: 435\n",
      "X51-1632.44m1-: Number of masks generated: 484\n",
      "X45-1897.86m1-: Number of masks generated: 701\n",
      "X46-1565.86m1-: Number of masks generated: 1073\n",
      "X41-2004.40m1-: Number of masks generated: 645\n",
      "X26-1423.23m1-: Number of masks generated: 544\n",
      "X51-1634.61m1-: Number of masks generated: 867\n",
      "X23-1583.81m1-: Number of masks generated: 459\n",
      "X48-1540.81m1-: Number of masks generated: 1525\n",
      "X10-1477.80m1-: Number of masks generated: 317\n",
      "X16-1984.17m1-: Number of masks generated: 452\n",
      "X46-1564.10m2-: Number of masks generated: 436\n",
      "X12-1932.50m1-: Number of masks generated: 802\n",
      "X159-1260.35m1-: Number of masks generated: 1130\n",
      "X48-1622.58m1-: Number of masks generated: 943\n",
      "X46-1565.60m2-: Number of masks generated: 823\n",
      "X26-2032.90m1-: Number of masks generated: 441\n",
      "X53-1692.80m1-: Number of masks generated: 725\n",
      "X44-2063.12m1-: Number of masks generated: 759\n",
      "X12-1806.90m1-: Number of masks generated: 474\n",
      "X159-1254.99m1-: Number of masks generated: 652\n",
      "X26-1781.50m1-: Number of masks generated: 415\n",
      "X46-1565.60m1-: Number of masks generated: 814\n",
      "X55-1713.70m1-: Number of masks generated: 553\n",
      "X53-1479.82m1-: Number of masks generated: 564\n",
      "X48-1542.48m1-: Number of masks generated: 1133\n",
      "X48-1843.48m2-: Number of masks generated: 629\n",
      "X159-1260.11m1-: Number of masks generated: 523\n",
      "X44-1712.23m1-: Number of masks generated: 558\n",
      "X48-1841.25m1-: Number of masks generated: 493\n",
      "X55-1494.90m1-: Number of masks generated: 1080\n",
      "X53-1653.33m1-: Number of masks generated: 1121\n",
      "X48-1842.93m1-: Number of masks generated: 808\n",
      "X46-1610.41m2-: Number of masks generated: 1040\n",
      "X46-1613.59m1-: Number of masks generated: 1132\n",
      "X21-1945.90m1-: Number of masks generated: 291\n",
      "X46-1564.10m3-: Number of masks generated: 421\n",
      "X53-1696.43m1-: Number of masks generated: 652\n",
      "X40-1996.90m1-: Number of masks generated: 366\n",
      "X27-1352.40m1-: Number of masks generated: 359\n",
      "X9-1303.11m1-: Number of masks generated: 368\n",
      "X43-1539.70m1-: Number of masks generated: 496\n",
      "X21-1652.99m1-: Number of masks generated: 478\n",
      "X159-1252.61m1-: Number of masks generated: 605\n",
      "X45-2114.00m1-: Number of masks generated: 531\n",
      "X53-1694.49m1-: Number of masks generated: 529\n",
      "X26-2029.00m1-: Number of masks generated: 462\n",
      "X41-1730.00m1-: Number of masks generated: 496\n",
      "X12-1889.50m1-: Number of masks generated: 804\n",
      "X46-1564.44m2-: Number of masks generated: 808\n",
      "X27-1547.75m1-: Number of masks generated: 394\n",
      "X51-1633.27m1-: Number of masks generated: 1351\n",
      "X46-1610.41m1-: Number of masks generated: 989\n",
      "X51-1631.60m1-: Number of masks generated: 699\n",
      "X53-1552.69m1-: Number of masks generated: 694\n",
      "X51-1859.10m2-: Number of masks generated: 692\n",
      "X23-1359.68m1-: Number of masks generated: 539\n",
      "X26-1293.00m1-: Number of masks generated: 1024\n",
      "X31-1595.00m1-: Number of masks generated: 949\n",
      "X18-1769.21m1-: Number of masks generated: 491\n",
      "X23-1356.59m1-: Number of masks generated: 394\n",
      "X46-1608.42m1-: Number of masks generated: 612\n",
      "X46-1564.44m1-: Number of masks generated: 915\n",
      "X48-1541.58m1-: Number of masks generated: 999\n",
      "X45-1895.59m1-: Number of masks generated: 721\n",
      "X53-1698.72m1-: Number of masks generated: 833\n",
      "X18-1546.90m1-: Number of masks generated: 600\n",
      "X31-1706.00m1-: Number of masks generated: 1054\n",
      "X26-1366.80m1-: Number of masks generated: 428\n",
      "X9-1832.87m1-: Number of masks generated: 523\n",
      "X48-1543.13m1-: Number of masks generated: 1427\n",
      "X26-1758.61m1-: Number of masks generated: 353\n",
      "X48-1838.12m1-: Number of masks generated: 605\n",
      "X51-1631.25m1-: Number of masks generated: 652\n",
      "X23-1358.65m1-: Number of masks generated: 274\n",
      "X51-1924.91m2-: Number of masks generated: 721\n",
      "X27-1479.85m1-: Number of masks generated: 527\n",
      "X21-1465.35m1-: Number of masks generated: 462\n",
      "X53-1653.62m1-: Number of masks generated: 1135\n",
      "X51-1924.91m1-: Number of masks generated: 723\n",
      "X9-1301.33m1-: Number of masks generated: 483\n",
      "X46-1564.10m1-: Number of masks generated: 882\n",
      "X51-1631.60m2-: Number of masks generated: 985\n",
      "X55-1493.30m1-: Number of masks generated: 818\n",
      "X55-1712.10m1-: Number of masks generated: 699\n",
      "X159-1259.50m1-: Number of masks generated: 519\n",
      "X20-1792.71m1-: Number of masks generated: 582\n",
      "X48-1540.81m2-: Number of masks generated: 1560\n",
      "X20-1919.41m1-: Number of masks generated: 504\n",
      "X46-1612.72m1-: Number of masks generated: 814\n",
      "X23-1357.55m1-: Number of masks generated: 484\n",
      "X44-2064.18m1-: Number of masks generated: 725\n",
      "X41-1732.40m1-: Number of masks generated: 316\n",
      "X159-1629.39m1-: Number of masks generated: 936\n",
      "X16-1985.27m1-: Number of masks generated: 563\n",
      "X45-2100.00m1-: Number of masks generated: 452\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from sklearn.cluster import KMeans\n",
    "from lora import LoRA_sam \n",
    "import copy\n",
    "\n",
    "# Function to visualize masks\n",
    "def save_anns(image, anns, save_path):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.imshow(image)\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:, :, 3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "# Save the mask to the specified folder\n",
    "def write_masks_to_folder(image, masks, path, image_suffix):\n",
    "    save_anns(image, masks, os.path.join(path, 'full_mask' + image_suffix))\n",
    "    for i, mask_data in enumerate(masks):\n",
    "        mask = mask_data[\"segmentation\"]\n",
    "        filename = f\"{i}\" + image_suffix\n",
    "        cv2.imwrite(os.path.join(path, filename), mask * 255)\n",
    "    return\n",
    "\n",
    "# Compute the bounding box of the mask\n",
    "def calculate_bbox(mask):\n",
    "    y_indices, x_indices = np.where(mask > 0)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        return None  # Empty mask\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "    return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "# Compute the IoU (Intersection over Union) of two bounding boxes\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    x1_min, y1_min, x1_max, y1_max = bbox1\n",
    "    x2_min, y2_min, x2_max, y2_max = bbox2\n",
    "\n",
    "    inter_xmin = max(x1_min, x2_min)\n",
    "    inter_ymin = max(y1_min, y2_min)\n",
    "    inter_xmax = min(x1_max, x2_max)\n",
    "    inter_ymax = min(y1_max, y2_max)\n",
    "\n",
    "    inter_width = max(0, inter_xmax - inter_xmin + 1)\n",
    "    inter_height = max(0, inter_ymax - inter_ymin + 1)\n",
    "    inter_area = inter_width * inter_height\n",
    "\n",
    "    bbox1_area = (x1_max - x1_min + 1) * (y1_max - y1_min + 1)\n",
    "    bbox2_area = (x2_max - x2_min + 1) * (y2_max - y2_min + 1)\n",
    "\n",
    "    iou = inter_area / float(bbox1_area + bbox2_area - inter_area)\n",
    "    return iou\n",
    "\n",
    "# NMS (Non-Maximum Suppression) filtering function\n",
    "def nms_filtering_optimized(cluster_indices, features, mask_dir, file_names, kmeans, labels, iou_threshold=0.3):\n",
    "    bboxes = []\n",
    "    distances = []\n",
    "    \n",
    "    for idx in cluster_indices:\n",
    "        mask_name = os.path.splitext(file_names[idx])[0] + '.png'\n",
    "        mask_path = os.path.join(mask_dir, mask_name)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        bbox = calculate_bbox(mask)\n",
    "        if bbox is not None:\n",
    "            bboxes.append((bbox, idx))\n",
    "            distance = np.linalg.norm(features[idx] - kmeans.cluster_centers_[labels[idx]])\n",
    "            distances.append(distance)\n",
    "    \n",
    "    sorted_indices = sorted(range(len(distances)), key=lambda i: distances[i])\n",
    "    keep_indices = []\n",
    "    while sorted_indices:\n",
    "        current_idx = sorted_indices.pop(0)\n",
    "        keep_indices.append(bboxes[current_idx][1])\n",
    "        current_bbox = bboxes[current_idx][0]\n",
    "        \n",
    "        sorted_indices = [\n",
    "            i for i in sorted_indices\n",
    "            if calculate_iou(current_bbox, bboxes[i][0]) <= iou_threshold\n",
    "        ]\n",
    "    \n",
    "    return keep_indices\n",
    "\n",
    "# 设置模型参数和路径\n",
    "sam_checkpoint = '/home/a6/vis/LDS/SAM/weights/sam_vit_h_4b8939.pth'\n",
    "lora_sam_checkpoint = '/home/a6/vis/LDS/SAM/logs/best_lora_cocenter_rank32.safetensors' \n",
    "model_type = 'vit_h'\n",
    "device = 'cuda'\n",
    "image_folder = '/home/a6/vis/LDS/segmentation/segformer-pytorch-master/VOCdevkit_pre/VOC2007/JPEGImages'\n",
    "val_file = 'train.txt'\n",
    "predict_dir = 'predict'\n",
    "\n",
    "# 创建模型，加载SAM权重用于生成掩码\n",
    "sam_model = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam_model.to(device=device)\n",
    "original_sam_model = copy.deepcopy(sam_model)\n",
    "\n",
    "# 使用LoRA微调的SAM模型生成图像的嵌入特征\n",
    "lora_sam_model = LoRA_sam(sam_model, rank=32)\n",
    "\n",
    "# 加载 LoRA 的权重\n",
    "lora_sam_model.load_lora_parameters(lora_sam_checkpoint)\n",
    "lora_sam_model.to(device)\n",
    "\n",
    "# 使用原始模型生成掩码\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    model=original_sam_model,\n",
    "    points_per_side=64,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.92,\n",
    "    crop_n_layers=2,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=100,\n",
    ")\n",
    "\n",
    "# 读取val.txt文件中的图像名称\n",
    "with open(val_file, 'r') as file:\n",
    "    image_names = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# 遍历图像名称列表\n",
    "for image_name in image_names:\n",
    "    image_path = os.path.join(image_folder, image_name + '.jpg')\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} not found, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # 加载图像\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (1024, 1024))\n",
    "\n",
    "    # 生成掩码\n",
    "    masks = mask_generator.generate(image)\n",
    "    print(f'{image_name}: Number of masks generated: {len(masks)}')\n",
    "\n",
    "    # 指定保存掩码的目录\n",
    "    masks_dir = f'{predict_dir}/masks/{image_name}'\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "    # 日志设置\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    output_dir = f'{predict_dir}/outputs'\n",
    "    mask_vec_npy_dir = os.path.join(output_dir, 'npy_masks', image_name)\n",
    "    os.makedirs(mask_vec_npy_dir, exist_ok=True)\n",
    "\n",
    "    # 将掩码保存到指定目录\n",
    "    write_masks_to_folder(image, masks, masks_dir, '.png')\n",
    "\n",
    "    # 转换图像格式以适应模型输入\n",
    "    image_torch = torch.as_tensor(image, device=device)\n",
    "    transformed_image = image_torch.permute(2, 0, 1).contiguous()[None, :, :, :]\n",
    "    input_image = lora_sam_model.sam.preprocess(transformed_image)\n",
    "    with torch.no_grad():\n",
    "        image_embedding = lora_sam_model.sam.image_encoder(input_image)  # [B, C, H, W]\n",
    "\n",
    "    b, c, h, w = image_embedding.shape\n",
    "\n",
    "    # 处理每个掩码并保存嵌入特征\n",
    "    mask_files = [f for f in os.listdir(masks_dir) if f.endswith('.png') and f != 'full_mask.png']\n",
    "    mask_vecs = []\n",
    "    for mask_file in mask_files:\n",
    "        mask_path = os.path.join(masks_dir, mask_file)\n",
    "        mask_name = os.path.splitext(mask_file)[0]\n",
    "        \n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        mask = torch.as_tensor(mask, device=device)[None, None, :, :]\n",
    "        \n",
    "        # 缩放特征和掩码\n",
    "        rescale_factor = 4\n",
    "        t1, t2 = int(mask.shape[2] / rescale_factor), int(mask.shape[3] / rescale_factor)\n",
    "        features_rescale = F.interpolate(image_embedding, size=[t1, t2], mode='bilinear')\n",
    "        mask_rescale = F.interpolate(mask, size=[t1, t2], mode='bilinear')\n",
    "\n",
    "        masked_feature = torch.mul(features_rescale, mask_rescale)\n",
    "        masked_feature = masked_feature.view(b, c, -1)\n",
    "        non_zero_count = torch.count_nonzero(masked_feature, dim=2)\n",
    "        \n",
    "        # 计算掩码的平均特征向量\n",
    "        masked_avg_vec = masked_feature.sum(dim=2) / non_zero_count\n",
    "        masked_avg_vec[torch.isnan(masked_avg_vec)] = 0\n",
    "        \n",
    "        # 保存掩码特征向量\n",
    "        npy_data = masked_avg_vec.detach().cpu().numpy()\n",
    "        single_mask_vec_path = os.path.join(mask_vec_npy_dir, mask_name + '.npy')\n",
    "        np.save(single_mask_vec_path, npy_data)\n",
    "        mask_vecs.append(npy_data)\n",
    "\n",
    "    # 将特征向量转换为 NumPy 数组\n",
    "    if len(mask_vecs) > 0:\n",
    "        mask_vecs = np.array(mask_vecs).squeeze()\n",
    "\n",
    "        # 对每张图像的掩码进行2分类聚类\n",
    "        kmeans = KMeans(n_clusters=2, random_state=0, n_init=100)\n",
    "        labels = kmeans.fit_predict(mask_vecs)\n",
    "\n",
    "        # 执行NMS过滤\n",
    "        cluster_indices_1 = np.where(labels == 0)[0]\n",
    "        cluster_indices_2 = np.where(labels == 1)[0]\n",
    "\n",
    "        filtered_cluster_indices_1 = nms_filtering_optimized(cluster_indices_1, mask_vecs, masks_dir, mask_files, kmeans, labels)\n",
    "        filtered_cluster_indices_2 = nms_filtering_optimized(cluster_indices_2, mask_vecs, masks_dir, mask_files, kmeans, labels)\n",
    "\n",
    "        # 创建图像对应的结果保存路径\n",
    "        results_dir = os.path.join(f'{predict_dir}/results', image_name)\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "        # 合并并保存聚类后的掩码\n",
    "        for cluster_id in range(2):  # 对每个聚类进行处理\n",
    "            combined_mask = np.zeros((1024, 1024), dtype=np.float32)\n",
    "            if cluster_id == 0:\n",
    "                selected_indices = filtered_cluster_indices_1\n",
    "            else:\n",
    "                selected_indices = filtered_cluster_indices_2\n",
    "\n",
    "            for idx in selected_indices:\n",
    "                mask_path = os.path.join(masks_dir, mask_files[idx])\n",
    "                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "                combined_mask = np.maximum(combined_mask, mask)\n",
    "            \n",
    "            # 保存聚类后的掩码\n",
    "            save_path = os.path.join(results_dir, f'{image_name}-{cluster_id + 1}.png')\n",
    "            cv2.imwrite(save_path, combined_mask * 255)\n",
    "\n",
    "        # 选择掩码数量较少的那张图像，并保存到一个新的文件夹\n",
    "        if len(filtered_cluster_indices_1) <= len(filtered_cluster_indices_2):\n",
    "            selected_mask = filtered_cluster_indices_1\n",
    "        else:\n",
    "            selected_mask = filtered_cluster_indices_2\n",
    "\n",
    "        combined_mask = np.zeros((1024, 1024), dtype=np.float32)\n",
    "        for idx in selected_mask:\n",
    "            mask_path = os.path.join(masks_dir, mask_files[idx])\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0\n",
    "            combined_mask = np.maximum(combined_mask, mask)\n",
    "\n",
    "        # 保存到新文件夹中，文件名为原图文件名\n",
    "        final_dir = os.path.join(predict_dir, 'final_results')\n",
    "        os.makedirs(final_dir, exist_ok=True)\n",
    "        final_save_path = os.path.join(final_dir, f'{image_name}.png')\n",
    "        cv2.imwrite(final_save_path, combined_mask * 255)\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
