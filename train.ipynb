{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from segment_anything import sam_model_registry\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from lora import LoRA_sam  \n",
    "\n",
    "# Set random seed\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the image encoder of SAM\n",
    "### 1. Define the SAM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6/anaconda3/envs/LDS/lib/python3.9/site-packages/segment_anything/build_sam.py:105: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LoRA_sam(\n",
       "  (sam): Sam(\n",
       "    (image_encoder): ImageEncoderViT(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-31): 32 x Block(\n",
       "          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): LoRA_qkv(\n",
       "              (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "              (linear_a_q): Linear(in_features=1280, out_features=32, bias=False)\n",
       "              (linear_b_q): Linear(in_features=32, out_features=1280, bias=False)\n",
       "              (linear_a_v): Linear(in_features=1280, out_features=32, bias=False)\n",
       "              (linear_b_v): Linear(in_features=32, out_features=1280, bias=False)\n",
       "            )\n",
       "            (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "            (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (neck): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): LayerNorm2d()\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (3): LayerNorm2d()\n",
       "      )\n",
       "    )\n",
       "    (prompt_encoder): PromptEncoder(\n",
       "      (pe_layer): PositionEmbeddingRandom()\n",
       "      (point_embeddings): ModuleList(\n",
       "        (0-3): 4 x Embedding(1, 256)\n",
       "      )\n",
       "      (not_a_point_embed): Embedding(1, 256)\n",
       "      (mask_downscaling): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LayerNorm2d()\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (4): LayerNorm2d()\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (no_mask_embed): Embedding(1, 256)\n",
       "    )\n",
       "    (mask_decoder): MaskDecoder(\n",
       "      (transformer): TwoWayTransformer(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x TwoWayAttentionBlock(\n",
       "            (self_attn): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn_token_to_image): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (cross_attn_image_to_token): Attention(\n",
       "              (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "              (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_attn_token_to_image): Attention(\n",
       "          (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (iou_token): Embedding(1, 256)\n",
       "      (mask_tokens): Embedding(4, 256)\n",
       "      (output_upscaling): Sequential(\n",
       "        (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (1): LayerNorm2d()\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "        (4): GELU(approximate='none')\n",
       "      )\n",
       "      (output_hypernetworks_mlps): ModuleList(\n",
       "        (0-3): 4 x MLP(\n",
       "          (layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (iou_prediction_head): MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lora_vit): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1280, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-31): 32 x Block(\n",
       "        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): LoRA_qkv(\n",
       "            (qkv): Linear(in_features=1280, out_features=3840, bias=True)\n",
       "            (linear_a_q): Linear(in_features=1280, out_features=32, bias=False)\n",
       "            (linear_b_q): Linear(in_features=32, out_features=1280, bias=False)\n",
       "            (linear_a_v): Linear(in_features=1280, out_features=32, bias=False)\n",
       "            (linear_b_v): Linear(in_features=32, out_features=1280, bias=False)\n",
       "          )\n",
       "          (proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "          (lin2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = 'vit_h'\n",
    "checkpoint = 'weights/sam_vit_h_4b8939.pth'\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Load the SAM model and initialize LoRA\n",
    "sam_model = sam_model_registry[model_type](checkpoint=checkpoint)\n",
    "sam_model.to(device)\n",
    "\n",
    "# Initialize the LoRA_sam model\n",
    "r = 32  # Rank of LoRA\n",
    "lora_sam_model = LoRA_sam(sam_model, rank=r)\n",
    "lora_sam_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Batch 0:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 0:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 1:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 2:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 3:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 4:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 5:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 6:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 7:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 8:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 9:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 10:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 11:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 12:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 13:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 14:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 15:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 16:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 17:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 18:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 19:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 20:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 21:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 22:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 23:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 24:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 25:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 26:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 27:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 28:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 29:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 30:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 31:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 32:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 33:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 34:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 35:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 36:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 37:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 38:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 39:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 40:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 41:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 42:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 43:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 44:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 45:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 46:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 47:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 48:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 49:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 50:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 51:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 52:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 53:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 54:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 55:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 56:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 57:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 58:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 59:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 60:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 61:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 62:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 63:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 64:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 65:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 66:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 67:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 68:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 69:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 70:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 71:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 72:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 73:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 74:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 75:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 76:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 77:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 78:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 79:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 80:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 81:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 82:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 83:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 84:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 85:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 86:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 87:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 88:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 89:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 90:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 91:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 92:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 93:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 94:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 95:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 96:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 97:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 98:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 99:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 100:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 101:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 102:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 103:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 104:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 105:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 106:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 107:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 108:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 109:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 110:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 111:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 112:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 113:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 114:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 115:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 116:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 117:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 118:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 119:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 120:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 121:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 122:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 123:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 124:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 125:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 126:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 127:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 128:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 129:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 130:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 131:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 132:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 133:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 134:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 135:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 136:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 137:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 138:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 139:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 140:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 141:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 142:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 143:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 144:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 145:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 146:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 147:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 148:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 149:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 150:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 151:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 152:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 153:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 154:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 155:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 156:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 157:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 158:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 159:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 160:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 161:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 162:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 163:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 164:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 165:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 166:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 167:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 168:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 169:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 170:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 171:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 172:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 173:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 174:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 175:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 176:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 177:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 178:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 179:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 180:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 181:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 182:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 183:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 184:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 185:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 186:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 187:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 188:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 189:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 190:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 191:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 192:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 193:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 194:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 195:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 196:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 197:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 198:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 199:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 200:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 201:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 202:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 203:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 204:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 205:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 206:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 207:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 208:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 209:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 210:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 211:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 212:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 213:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 214:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 215:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 216:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 217:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 218:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 219:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 220:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 221:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 222:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 223:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 224:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 225:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 226:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 227:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 228:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 229:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 230:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 231:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 232:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 233:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 234:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 235:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 236:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 237:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 238:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 239:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 240:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n",
      "Val Batch 241:\n",
      "Images shape: torch.Size([1, 3, 1024, 1024])\n",
      "Masks shape: torch.Size([1, 256, 256])\n",
      "Mask unique values: tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Read the training and validation set lists\n",
    "def read_split_files(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        file_names = f.read().strip().split('\\n')\n",
    "    return file_names\n",
    "\n",
    "# Dataset loading\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, sam_model, file_list, mask_size=(256, 256), device='cpu'):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.sam_model = sam_model\n",
    "        self.mask_size = mask_size\n",
    "        self.device = device\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.png') and f.replace('.png', '') in file_list]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read image\n",
    "        image_file = self.image_files[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_file)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (1024, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Read mask\n",
    "        mask_file = image_file.replace('.png', '.png')\n",
    "        mask_path = os.path.join(self.mask_dir, mask_file)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        mask = cv2.resize(mask, self.mask_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Convert to torch tensor\n",
    "        input_image_torch = torch.as_tensor(image, dtype=torch.float32).to(self.device)\n",
    "        input_image_torch = input_image_torch.permute(2, 0, 1).contiguous()  # [C, H, W]\n",
    "\n",
    "        # Preprocessing step for SAM model\n",
    "        input_image = self.sam_model.preprocess(input_image_torch.to(self.device))\n",
    "\n",
    "        # Convert mask to torch tensor\n",
    "        mask = torch.as_tensor(mask, dtype=torch.long).to(self.device)  # Mask is single-channel\n",
    "\n",
    "        return input_image, mask\n",
    "\n",
    "# Create dataset instances for training and validation sets\n",
    "# Set paths\n",
    "image_dir = 'datasets/images'\n",
    "mask_dir = 'datasets/masks'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Read file name lists\n",
    "train_files = read_split_files('datasets/train.txt')\n",
    "val_files = read_split_files('datasets/val.txt')\n",
    "\n",
    "# Create dataset and data loader for training and validation sets\n",
    "train_dataset = SegmentationDataset(image_dir, mask_dir, sam_model, train_files, device=device)\n",
    "val_dataset = SegmentationDataset(image_dir, mask_dir, sam_model, val_files, device=device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Test the data loader\n",
    "for i, (images, masks) in enumerate(train_loader):\n",
    "    print(f'Train Batch {i}:')\n",
    "    print(f'Images shape: {images.shape}')  # Should be [B, C, H, W]\n",
    "    print(f'Masks shape: {masks.shape}')    # Should be [B, H, W]\n",
    "    print(f'Mask unique values: {torch.unique(masks)}')  # Output unique values in the mask\n",
    "    break\n",
    "\n",
    "for i, (images, masks) in enumerate(val_loader):\n",
    "    print(f'Val Batch {i}:')\n",
    "    print(f'Images shape: {images.shape}')  # Should be [B, C, H, W]\n",
    "    print(f'Masks shape: {masks.shape}')    # Should be [B, H, W]\n",
    "    print(f'Mask unique values: {torch.unique(masks)}')  # Output unique values in the mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Contrastive Center Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveCenterLoss(nn.Module):\n",
    "    \"\"\"Contrastive Center Loss.\n",
    "    \n",
    "    This loss combines the concepts of Center Loss and Contrastive Loss,\n",
    "    considering both intra-class compactness and inter-class separability.\n",
    "    \n",
    "    Parameters:\n",
    "        num_classes (int): Number of classes.\n",
    "        feat_dim (int): Dimension of features.\n",
    "        use_gpu (bool): Whether to use GPU.\n",
    "        lambda_c (float): Weight of the center loss part.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=2, feat_dim=256, use_gpu=True, lambda_c=1.0):\n",
    "        super(ContrastiveCenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.use_gpu = use_gpu\n",
    "        self.lambda_c = lambda_c\n",
    "\n",
    "        # Initialize class centers\n",
    "        if self.use_gpu:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).cuda())\n",
    "        else:\n",
    "            self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim))\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Forward propagation function.\n",
    "        \n",
    "        Parameters:\n",
    "            x: Feature matrix, shape (batch_size, feat_dim).\n",
    "            labels: Ground truth labels, shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Compute distance between each feature and all class centers\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "        distmat.addmm_(x, self.centers.t(), beta=1, alpha=-2)\n",
    "        \n",
    "        # Create a mask for the class labels\n",
    "        classes = torch.arange(self.num_classes).long()\n",
    "        if self.use_gpu: classes = classes.cuda()\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        # Compute intra-class distances (distance to the correct class center)\n",
    "        intra_distances = distmat * mask.float()\n",
    "        intra_distances = intra_distances.sum() / batch_size\n",
    "\n",
    "        # Compute inter-class distances (distance to incorrect class centers)\n",
    "        inter_distances = distmat * (~mask).float()\n",
    "        inter_distances = inter_distances.sum() / (batch_size * (self.num_classes - 1))\n",
    "        \n",
    "        # Compute the contrastive center loss\n",
    "        loss = (self.lambda_c / 2.0) * intra_distances / (inter_distances + 1e-6) / 0.1\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [Train]:   0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception occurred during epoch 1: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 23.63 GiB of which 119.94 MiB is free. Process 111447 has 17.12 GiB memory in use. Including non-PyTorch memory, this process has 6.39 GiB memory in use. Of the allocated memory 5.67 GiB is allocated by PyTorch, and 280.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the function to compute loss\n",
    "def compute_loss(class_logits, masks, upsampled_embedding, alpha, loss_fn, contrastive_center_loss, ce_weight=1.0, center_weight=1.0):\n",
    "    \"\"\"\n",
    "    Compute cross-entropy loss and contrastive center loss, and combine them with given weights.\n",
    "\n",
    "    Args:\n",
    "        class_logits (Tensor): Classification results (B, num_classes, 256, 256)\n",
    "        masks (Tensor): Masks (B, 256, 256)\n",
    "        upsampled_embedding (Tensor): Upsampled embeddings (B, 256, 256, 256)\n",
    "        alpha (float): Weight of contrastive center loss\n",
    "        loss_fn (nn.Module): Cross-entropy loss function\n",
    "        contrastive_center_loss (ContrastiveCenterLoss): Instance of contrastive center loss function\n",
    "        ce_weight (float): Weight of cross-entropy loss\n",
    "        center_weight (float): Weight of contrastive center loss\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Total loss\n",
    "        Tensor: Cross-entropy loss value\n",
    "        Tensor: Contrastive center loss value\n",
    "    \"\"\"\n",
    "    # Compute cross-entropy loss\n",
    "    loss_ce = loss_fn(class_logits, masks.long())\n",
    "    \n",
    "    # Compute contrastive center loss\n",
    "    loss_cent = contrastive_center_loss(upsampled_embedding.view(-1, 256), masks.view(-1)) * alpha\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = ce_weight * loss_ce + center_weight * loss_cent\n",
    "    \n",
    "    return total_loss, loss_ce.item(), loss_cent.item()\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(filename='logs/best_model_ce_cocenter_lora.log', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define cross-entropy loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define a custom model with only one convolutional layer\n",
    "class FeatureMapper(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FeatureMapper, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "    \n",
    "# Instantiate contrastive center loss and the custom model\n",
    "contrastive_center_loss = ContrastiveCenterLoss(num_classes=2, feat_dim=256, use_gpu=torch.cuda.is_available())\n",
    "model = FeatureMapper(in_channels=256, out_channels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Freeze all SAM model parameters, unfreeze only LoRA layers and custom convolution layer\n",
    "for param in lora_sam_model.sam.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for layer in lora_sam_model.A_weights + lora_sam_model.B_weights:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(filter(lambda p: p.requires_grad, lora_sam_model.parameters())) + list(model.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Define a separate optimizer for contrastive center loss\n",
    "optimizer_centloss = torch.optim.Adam(contrastive_center_loss.parameters(), lr=0.5)\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100\n",
    "best_val_loss = float('inf')\n",
    "best_epoch = 0\n",
    "checkpoint_path = 'logs/best_model_ce_lora.pth'  # Replace with actual path\n",
    "alpha = 0.5 # Weight for center loss\n",
    "\n",
    "# Define Warmup + custom cosine annealing learning rate scheduler\n",
    "warmup_epochs = 10  # Number of epochs for warmup\n",
    "min_lr_factor = 0.01  # Minimum learning rate is 1% of the maximum\n",
    "\n",
    "def lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return float(epoch / warmup_epochs)\n",
    "    else:\n",
    "        cosine_decay = 0.5 * (1 + torch.cos(torch.tensor(epoch - warmup_epochs) * torch.pi / (num_epochs - warmup_epochs)))\n",
    "        return float(min_lr_factor + (1 - min_lr_factor) * cosine_decay)\n",
    "    \n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda)\n",
    "scheduler_centloss = lr_scheduler.LambdaLR(optimizer_centloss, lr_lambda=lr_lambda)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    try:\n",
    "        # Set model to training mode\n",
    "        lora_sam_model.train()\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0  # Accumulate total loss for each batch\n",
    "        total_loss_ce = 0  # Accumulate cross-entropy loss for each batch\n",
    "        total_loss_cent = 0  # Accumulate contrastive center loss for each batch\n",
    "        num_batches = 0\n",
    "\n",
    "        # Training phase\n",
    "        for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Train]\"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            # Forward pass: Get image embeddings\n",
    "            image_embedding = lora_sam_model.sam.image_encoder(images)  # B, 256, 64, 64\n",
    "\n",
    "            # Upsample to (B, 256, 256, 256)\n",
    "            upsampled_embedding = F.interpolate(image_embedding, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "            # Process embeddings using the custom model\n",
    "            class_logits = model(upsampled_embedding)  # B, num_classes, 256, 256\n",
    "\n",
    "            # Compute total loss, including cross-entropy loss and contrastive center loss\n",
    "            loss, loss_ce, loss_cent = compute_loss(\n",
    "                class_logits, masks, upsampled_embedding, alpha, loss_fn, contrastive_center_loss\n",
    "            )\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_centloss.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # To eliminate alpha's influence on center point updates, multiply by (1./alpha)\n",
    "            for param in contrastive_center_loss.parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad.data *= (1. / alpha)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer_centloss.step()\n",
    "\n",
    "            # Accumulate losses\n",
    "            total_loss += loss.item()\n",
    "            total_loss_ce += loss_ce\n",
    "            total_loss_cent += loss_cent\n",
    "            num_batches += 1\n",
    "\n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "        scheduler_centloss.step()\n",
    "\n",
    "        # Calculate average loss\n",
    "        avg_train_loss = total_loss / num_batches\n",
    "        avg_train_loss_ce = total_loss_ce / num_batches\n",
    "        avg_train_loss_cent = total_loss_cent / num_batches\n",
    "\n",
    "        # Set model to evaluation mode\n",
    "        lora_sam_model.eval()\n",
    "        model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "        val_loss_ce = 0\n",
    "        val_loss_cent = 0\n",
    "        num_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            for images, masks in tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} [Validation]\"):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "                # Forward pass: Get image embeddings\n",
    "                image_embedding = lora_sam_model.sam.image_encoder(images)  # B, 256, 64, 64\n",
    "\n",
    "                # Upsample to (B, 256, 256, 256)\n",
    "                upsampled_embedding = F.interpolate(image_embedding, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "\n",
    "                # Process embeddings using the custom model\n",
    "                class_logits = model(upsampled_embedding)  # B, num_classes, 256, 256\n",
    "\n",
    "                # Compute total loss, including cross-entropy loss and contrastive center loss\n",
    "                loss, loss_ce, loss_cent = compute_loss(\n",
    "                    class_logits, masks, upsampled_embedding, alpha, loss_fn, contrastive_center_loss\n",
    "                )\n",
    "\n",
    "                # Accumulate losses\n",
    "                val_loss += loss.item()\n",
    "                val_loss_ce += loss_ce\n",
    "                val_loss_cent += loss_cent\n",
    "                num_val_batches += 1\n",
    "\n",
    "        avg_val_loss = val_loss / num_val_batches\n",
    "        avg_val_loss_ce = val_loss_ce / num_val_batches\n",
    "        avg_val_loss_cent = val_loss_cent / num_val_batches\n",
    "\n",
    "        # Get current learning rate\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        current_lr_centloss = optimizer_centloss.param_groups[0]['lr']\n",
    "\n",
    "        # Output and log training/validation losses and current learning rates\n",
    "        logging.info(f\"Epoch [{epoch + 1}/{num_epochs}], Learning Rate: {current_lr:.6f}, Center Loss Learning Rate: {current_lr_centloss:.6f}, \"\n",
    "                     f\"Average Train Loss: {avg_train_loss:.4f}, Average Val Loss: {avg_val_loss:.4f}, \"\n",
    "                     f\"Train CE Loss: {avg_train_loss_ce:.4f}, Train Center Loss: {avg_train_loss_cent:.4f}, \"\n",
    "                     f\"Val CE Loss: {avg_val_loss_ce:.4f}, Val Center Loss: {avg_val_loss_cent:.4f}\")\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Learning Rate: {current_lr:.6f}, Center Loss Learning Rate: {current_lr_centloss:.6f}, \"\n",
    "              f\"Average Train Loss: {avg_train_loss:.4f}, Average Val Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Train CE Loss: {avg_train_loss_ce:.4f}, Train Center Loss: {avg_train_loss_cent:.4f}, \"\n",
    "              f\"Val CE Loss: {avg_val_loss_ce:.4f}, Val Center Loss: {avg_val_loss_cent:.4f}\")\n",
    "\n",
    "\n",
    "        # Save the model with the best validation performance\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch + 1\n",
    "            # Save LoRA and classifier weights\n",
    "            lora_sam_model.save_lora_parameters(f'logs/best_lora_cocenter_rank{r}.safetensors')\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "            logging.info(f\"Best model saved at epoch {best_epoch} with val loss {best_val_loss:.4f}\")\n",
    "            print(f\"Best model saved at epoch {best_epoch} with val loss {best_val_loss:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Exception occurred during epoch {epoch + 1}: {str(e)}\")\n",
    "        print(f\"Exception occurred during epoch {epoch + 1}: {str(e)}\")\n",
    "        lora_sam_model.save_lora_parameters(f'logs/error_lora_epoch_{epoch + 1}.safetensors')\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "        }, f'logs/error_model_epoch_{epoch + 1}.pth')\n",
    "        break\n",
    "\n",
    "logging.info(\"Training completed\")\n",
    "print(\"Training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
